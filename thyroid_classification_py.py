# -*- coding: utf-8 -*-
"""thyroid_classification.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/thyroid-classification-py-3532c097-e459-4c9a-8de0-4c5f01bc6868.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240208/auto/storage/goog4_request%26X-Goog-Date%3D20240208T164030Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5a315e5a2f9e2563a5042af74bb8b96099e992a9b23e74dae8ce40dd367eb6779b4fe01bbb786301b828a6142c1661003bf383a9a6e91999c0192dd5ced4aa738fde0b7edad30c70f4c49ed05d00d2fd70da60a7ef618e91c5f53b3f99062e332bb965ddcb5f503efdbe2df34b874d04fd1bc32010595d136a8784bb66c562685aa84f9dd64cd640bd4767db51042efed7723ff5874ac48bca4120ae19eb337356d66a99ae0245addbd6f78bb32c0542f92fb3be56f99ad269ae6d9e3d496b427e98c5ffb3a42d015134afba1e572a569329aff52f484c2a524b87bc760fd715a0c5bd0d4164797c355225d779173519e270d36a11742f3a5601d9a5d2566993
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'thyroid-disease-data-set:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1027034%2F1730566%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240208%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240208T164030Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D90e9394ce1f6751a171958a51196f6d641e3d9feb4bd569aa809ae034b8c24f24ab7aba5ca46cdd32a791f59d37867e7c9ccf18aa0491c6e0c0db63e2621b2c0c3664eeb9be981a93d1b5a7827e2502a8288fde01b0553b2783953fb5ae5fd5d4c066652fb4f6ecf3a178ea329472cbdd4ccf692d99a9e2cbb995741938a5c183bfba8d8ca14c291eca209a53bbc56806511bd177cd1a94bae02b2adad38f98dd7640bb980a8c0819f24c3ca66758ae9bdb4f23ffdba1e65b07209a4d72bb9f94857efddd4e16c623e78872b8939f05493bfd9a84797b00e925a5846c045fee43f8aa3ea87c3c1654dd3d874990d0f65f7f01975c4d8996095039fd7221c286f,html-files:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4417438%2F7589054%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240208%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240208T164030Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D81fe9c7965556a137cdc0a935a10bb121369fb4bccdeb17be5316b57cdeab8b374505b440bc2c3ae9ad131e995920cb400231a0dd645e91bd1b2797a259c7092a455f07eaec91d39fed1b7bfb065196e216ae0b5eab352a10daa002c19daf8b672067bf899210e84d657b6a5509fddea0908a087fd26ce44d9cf1ac3448d82e265399cf3c58b99e9e9e358361649cd2949c013e7f7b89a3b38c671406a790507b61406a570f69eb60600835bfe61070a7c211146b4af669a75eee6508e5653ae0a037b50c565d6ccb021869fe1e44043f93b8de7aa165425943eeacfca9c141c3a1d008af4baebb616fa3ee964c7942846ce2f5ac09741d3612686f07eb105e8'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""## **Import Libraries**"""

#pandas
import pandas as pd

#numpy
import numpy as np

#matplotlib
import matplotlib.pyplot as plt

#seaborn
import seaborn as sns

#sklearn
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report,f1_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import pickle
import warnings
warnings.filterwarnings('ignore')

"""## **Read data from csv**"""

thyroid_df = pd.read_csv('../input/thyroid-disease-data-set/hypothyroid.csv')
thyroid_df.head()

"""## **Data Cleaning**"""

thyroid_df.rename(columns={'binaryClass':'Label'},inplace=True)

thyroid_df.replace('?',np.nan,inplace=True)

thyroid_df.drop(['T3 measured','TSH measured','TT4 measured','T4U measured','FTI measured','TBG measured','TBG','referral source','on thyroxine','query on thyroxine','on antithyroid medication','query hypothyroid', 'query hyperthyroid','hypopituitary', 'psych'],axis=1,inplace=True)

thyroid_df.info()

thyroid_df['thyroid surgery'].value_counts()

cols = ['age','FTI','TSH','T3','TT4','T4U']
for i in cols:
    thyroid_df[i] = pd.to_numeric(thyroid_df[i])

thyroid_df.info()

"""## **Handle Missing Values**"""

thyroid_df.isnull().sum()

miss_cols = ['FTI','TSH','T3','TT4','T4U']
for i in miss_cols:
    thyroid_df[i] = thyroid_df[i].fillna(thyroid_df[i].mean())

thyroid_df.dropna(inplace=True)

thyroid_df.isnull().sum()

thyroid_df = thyroid_df.drop(1364)

thyroid_df.TT4 = thyroid_df.TT4.astype(int)
thyroid_df.FTI = thyroid_df.FTI.astype(int)
thyroid_df.age = thyroid_df.age.astype(int)

"""## **EDA**"""

sns.countplot(x='Label',data=thyroid_df)
plt.title("Countplot for Target variable");

positive_df = thyroid_df[thyroid_df.Label=='P']

plt.figure(figsize=(9,6))
sns.histplot(x='age',data=positive_df,color='blue')
plt.title("Distribution of Positive Class Based on Age",{'fontsize':20});

plt.figure(figsize=(10,8))
plt.pie(x=positive_df.sex.value_counts(),
        labels=['Female','Male'],
        startangle = 90,
        colors=['springgreen','orange'],
        autopct='%.2f'
       );
plt.legend();

"""## **Inference :**
### Female patients who has disease is greater than male patients.
"""

plt.figure(figsize=(8,8))
plt.pie(x=positive_df.sick.value_counts(),
        labels=['Sick','Well'],
        startangle = 20,
        colors=['deepskyblue','red'],
        autopct='%.2f',
        explode=[0,0.2]
       );
plt.legend();

X = thyroid_df.drop('Label',axis=1)
y = thyroid_df.Label

"""## **Transform non-numerical labels to numerical labels.**"""

s_encoder = LabelEncoder()
si_encoder = LabelEncoder()
preg_encoder = LabelEncoder()
th_encoder = LabelEncoder()
treat_encoder = LabelEncoder()
lith_encoder = LabelEncoder()
g_encoder= LabelEncoder()
tu_encoder = LabelEncoder()

X['sex'] = s_encoder.fit_transform(X.sex)
X['I131 treatment'] = treat_encoder.fit_transform(X['I131 treatment'])
X['sick'] = si_encoder.fit_transform(X.sick)
X['pregnant'] = preg_encoder.fit_transform(X.pregnant)
X['thyroid surgery'] = th_encoder.fit_transform(X['thyroid surgery'])
X['lithium'] = lith_encoder.fit_transform(X['lithium'])
X['goitre'] = g_encoder.fit_transform(X['goitre'])
X['tumor'] = tu_encoder.fit_transform(X['tumor'])

def func(df):
    if df == 'P':
        return 1
    else:
        return 0

y = y.apply(func)

"""## **Split original data into training data and testing data.**"""

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=11)

"""## **Handle Imbalance Data**"""

smote = SMOTE(random_state=11)

x_smote, y_smote = smote.fit_resample(X_train, y_train)

print("Shape before the Oversampling : ",X_train.shape)
print("Shape after the Oversampling : ",x_smote.shape)

"""Scaling (Normalization)"""

scalr = MinMaxScaler()
x_smote.TT4 = scalr.fit_transform(x_smote[['TT4']])
x_smote.age = scalr.fit_transform(x_smote[['age']])
x_smote.FTI = scalr.fit_transform(x_smote[['FTI']])

print(X_test.columns)

X_test.TT4 = scalr.fit_transform(X_test[['TT4']])
X_test.age = scalr.fit_transform(X_test[['age']])
X_test.FTI = scalr.fit_transform(X_test[['FTI']])

"""## **Build Models.**"""

models = {
    LogisticRegression(max_iter=500):'Logistic Regression',
    SVC():"Support Vector Machine",
    RandomForestClassifier():'Random Forest'
}
for m in models.keys():
    m.fit(x_smote,y_smote)
for model,name in models.items():
     print(f"Accuracy Score for {name} is : ",model.score(X_test,y_test)*100,"%")

"""## **Inference :**
### The most of patients who suffer from thyroid belonging to age group between 50-70

## **Classification Report for each model.**
"""

for model,name in models.items():
    y_pred = model.predict(X_test)
    print(f"Classification Report for {name}")
    print("----------------------------------------------------------")
    print(classification_report(y_test,y_pred))
    print("----------------------------------------------------------")

rf = RandomForestClassifier()
rf.fit(x_smote,y_smote)
rf.score(X_test,y_test)

plt.figure(figsize=(9,7))
feature_imp1 = rf.feature_importances_
sns.barplot(x=feature_imp1, y=X.columns)
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.title("Visualizing Important Features For Random Forest ",{'fontsize':25})
plt.show();

x_smote.drop(['sick', 'pregnant', 'I131 treatment',
              'lithium', 'goitre', 'tumor'], axis=1, inplace=True)
X_test.drop(['sick', 'pregnant', 'I131 treatment',
              'lithium', 'goitre', 'tumor'], axis=1, inplace=True)

new_rf = RandomForestClassifier()
new_rf.fit(x_smote,y_smote)
new_rf.score(X_test,y_test)

thyroid_df.head()

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 5, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

rf_classifier = RandomForestClassifier(random_state=11)
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
best_score = grid_search.best_score_
print("Best Parameters:", best_params)
print("Best Score:", best_score)



